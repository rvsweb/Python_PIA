{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Predecir la supervivencia del Titanic\n",
        "\n",
        "@autor : Raul Vela.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "########### LIBRERIAS A UTILIZAR \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "########### IMPORTAR LOS DATOS\n",
        "\n",
        "# Importamos los datos a utilizar desde la web oficial de Kaggle\n",
        "url_test = 'G:\\\\Otros ordenadores\\\\Mi PC\\\\CURSO BD & IA\\\\Python_PIA2\\\\SAA\\\\2_2_Titanic\\\\content\\\\test.csv'\n",
        "url_train = 'G:\\\\Otros ordenadores\\\\Mi PC\\CURSO BD & IA\\\\Python_PIA2\\\\SAA\\\\2_2_Titanic\\\\content\\\\train.csv'\n",
        "\n",
        "df_test = pd.read_csv(url_test)\n",
        "df_train = pd.read_csv(url_train)\n",
        "\n",
        "#Se guardan los datos en un archivo para siempre tenerlos disponibles\n",
        "dir_test = 'G:\\\\Otros ordenadores\\\\Mi PC\\\\CURSO BD & IA\\\\Python_PIA2\\\\SAA\\\\2_2_Titanic\\\\content\\\\titanic_test.csv'\n",
        "dir_train = 'G:\\\\Otros ordenadores\\\\Mi PC\\\\CURSO BD & IA\\\\Python_PIA2\\\\SAA\\\\2_2_Titanic\\\\content\\\\titanic_train.csv'\n",
        "\n",
        "df_test.to_csv(dir_test)\n",
        "df_train.to_csv(dir_train)\n",
        "\n",
        "#Importar los datos de los archivos .csv almacenados\n",
        "df_test = pd.read_csv(dir_test)\n",
        "df_train = pd.read_csv(dir_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de datos:\n",
            "(891, 13)\n",
            "(418, 12)\n",
            "Tipos de datos:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 13 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Unnamed: 0   891 non-null    int64  \n",
            " 1   PassengerId  891 non-null    int64  \n",
            " 2   Survived     891 non-null    int64  \n",
            " 3   Pclass       891 non-null    int64  \n",
            " 4   Name         891 non-null    object \n",
            " 5   Sex          891 non-null    object \n",
            " 6   Age          714 non-null    float64\n",
            " 7   SibSp        891 non-null    int64  \n",
            " 8   Parch        891 non-null    int64  \n",
            " 9   Ticket       891 non-null    object \n",
            " 10  Fare         891 non-null    float64\n",
            " 11  Cabin        204 non-null    object \n",
            " 12  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(6), object(5)\n",
            "memory usage: 90.6+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Unnamed: 0   418 non-null    int64  \n",
            " 1   PassengerId  418 non-null    int64  \n",
            " 2   Pclass       418 non-null    int64  \n",
            " 3   Name         418 non-null    object \n",
            " 4   Sex          418 non-null    object \n",
            " 5   Age          332 non-null    float64\n",
            " 6   SibSp        418 non-null    int64  \n",
            " 7   Parch        418 non-null    int64  \n",
            " 8   Ticket       418 non-null    object \n",
            " 9   Fare         417 non-null    float64\n",
            " 10  Cabin        91 non-null     object \n",
            " 11  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 39.3+ KB\n",
            "None\n",
            "Datos faltantes:\n",
            "Unnamed: 0       0\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "Unnamed: 0       0\n",
            "PassengerId      0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n",
            "Estadísticas del dataset:\n",
            "       Unnamed: 0  PassengerId    Survived      Pclass         Age  \\\n",
            "count  891.000000   891.000000  891.000000  891.000000  714.000000   \n",
            "mean   445.000000   446.000000    0.383838    2.308642   29.699118   \n",
            "std    257.353842   257.353842    0.486592    0.836071   14.526497   \n",
            "min      0.000000     1.000000    0.000000    1.000000    0.420000   \n",
            "25%    222.500000   223.500000    0.000000    2.000000   20.125000   \n",
            "50%    445.000000   446.000000    0.000000    3.000000   28.000000   \n",
            "75%    667.500000   668.500000    1.000000    3.000000   38.000000   \n",
            "max    890.000000   891.000000    1.000000    3.000000   80.000000   \n",
            "\n",
            "            SibSp       Parch        Fare  \n",
            "count  891.000000  891.000000  891.000000  \n",
            "mean     0.523008    0.381594   32.204208  \n",
            "std      1.102743    0.806057   49.693429  \n",
            "min      0.000000    0.000000    0.000000  \n",
            "25%      0.000000    0.000000    7.910400  \n",
            "50%      0.000000    0.000000   14.454200  \n",
            "75%      1.000000    0.000000   31.000000  \n",
            "max      8.000000    6.000000  512.329200  \n",
            "       Unnamed: 0  PassengerId      Pclass         Age       SibSp  \\\n",
            "count  418.000000   418.000000  418.000000  332.000000  418.000000   \n",
            "mean   208.500000  1100.500000    2.265550   30.272590    0.447368   \n",
            "std    120.810458   120.810458    0.841838   14.181209    0.896760   \n",
            "min      0.000000   892.000000    1.000000    0.170000    0.000000   \n",
            "25%    104.250000   996.250000    1.000000   21.000000    0.000000   \n",
            "50%    208.500000  1100.500000    3.000000   27.000000    0.000000   \n",
            "75%    312.750000  1204.750000    3.000000   39.000000    1.000000   \n",
            "max    417.000000  1309.000000    3.000000   76.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  418.000000  417.000000  \n",
            "mean     0.392344   35.627188  \n",
            "std      0.981429   55.907576  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.895800  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.500000  \n",
            "max      9.000000  512.329200  \n"
          ]
        }
      ],
      "source": [
        "########### ENTENDIMIENTO DE LOS DATOS\n",
        "\n",
        "#Verifico la cantidad de datos que hay en los dataset\n",
        "print('Cantidad de datos:')\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)\n",
        "#Verifico el tipo de datos contenida en ambos dataset\n",
        "print('Tipos de datos:')\n",
        "print(df_train.info())\n",
        "print(df_test.info())\n",
        "#Verifico los datos faltantes de los dataset\n",
        "print('Datos faltantes:')\n",
        "print(pd.isnull(df_train).sum())\n",
        "print(pd.isnull(df_test).sum())\n",
        "#Verifico las estadísticas del dataset\n",
        "print('Estadísticas del dataset:')\n",
        "print(df_train.describe())\n",
        "print(df_test.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29.69911764705882\n",
            "30.272590361445783\n",
            "Unnamed: 0    0\n",
            "Survived      0\n",
            "Pclass        0\n",
            "Sex           0\n",
            "Age           0\n",
            "SibSp         0\n",
            "Parch         0\n",
            "Fare          0\n",
            "Embarked      0\n",
            "dtype: int64\n",
            "Unnamed: 0     0\n",
            "PassengerId    0\n",
            "Pclass         0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n",
            "(889, 9)\n",
            "(417, 9)\n",
            "   Unnamed: 0  PassengerId  Pclass  Sex Age  SibSp  Parch     Fare  Embarked\n",
            "0           0          892       3    1   5      0      0   7.8292         0\n",
            "1           1          893       3    0   6      1      0   7.0000         1\n",
            "2           2          894       2    1   7      0      0   9.6875         0\n",
            "3           3          895       3    1   5      0      0   8.6625         1\n",
            "4           4          896       3    0   4      1      1  12.2875         1\n",
            "   Unnamed: 0  Survived  Pclass  Sex Age  SibSp  Parch     Fare  Embarked\n",
            "0           0         0       3    1   4      1      0   7.2500       1.0\n",
            "1           1         1       1    0   5      1      0  71.2833       2.0\n",
            "2           2         1       3    0   5      0      0   7.9250       1.0\n",
            "3           3         1       1    0   5      1      0  53.1000       1.0\n",
            "4           4         0       3    1   5      0      0   8.0500       1.0\n"
          ]
        }
      ],
      "source": [
        "##########PREPROCESAMIENTO DE LA DATA \n",
        "\n",
        "#Cambio los datos de sexos en números\n",
        "df_train['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
        "df_test['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
        "\n",
        "#Cambio los datos de embarque en números\n",
        "df_train['Embarked'].replace(['Q','S', 'C'],[0,1,2],inplace=True)\n",
        "df_test['Embarked'].replace(['Q','S', 'C'],[0,1,2],inplace=True)\n",
        "\n",
        "#Reemplazo los datos faltantes en la edad por la media de esta columna\n",
        "print(df_train[\"Age\"].mean())\n",
        "print(df_test[\"Age\"].mean())\n",
        "promedio = 30\n",
        "df_train['Age'] = df_train['Age'].replace(np.nan, promedio)\n",
        "df_test['Age'] = df_test['Age'].replace(np.nan, promedio)\n",
        "\n",
        "#Creo varios grupos de acuerdo a bandas de las edades\n",
        "#Bandas: 0-8, 9-15, 16-18, 19-25, 26-40, 41-60, 61-100\n",
        "bins = [0, 8, 15, 18, 25, 40, 60, 100]\n",
        "names = ['1', '2', '3', '4', '5', '6', '7']\n",
        "df_train['Age'] = pd.cut(df_train['Age'], bins, labels = names)\n",
        "df_test['Age'] = pd.cut(df_test['Age'], bins, labels = names)\n",
        "\n",
        "#Se elimina la columna de \"Cabin\" ya que tiene muchos datos perdidos\n",
        "df_train.drop(['Cabin'], axis = 1, inplace=True)\n",
        "df_test.drop(['Cabin'], axis = 1, inplace=True)\n",
        "\n",
        "#Elimino las columnas que considero que no son necesarias para el analisis\n",
        "df_train = df_train.drop(['PassengerId','Name','Ticket'], axis=1)\n",
        "df_test = df_test.drop(['Name','Ticket'], axis=1)\n",
        "\n",
        "#Se elimina las filas con los datos perdidos\n",
        "df_train.dropna(axis=0, how='any', inplace=True)\n",
        "df_test.dropna(axis=0, how='any', inplace=True)\n",
        "\n",
        "#Verifico los datos\n",
        "print(pd.isnull(df_train).sum())\n",
        "print(pd.isnull(df_test).sum())\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)\n",
        "\n",
        "print(df_test.head())\n",
        "print(df_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión Regresión Logística:\n",
            "0.7651195499296765\n",
            "Precisión Soporte de Vectores:\n",
            "0.6568213783403657\n",
            "Precisión Vecinos más Cercanos:\n",
            "0.8171589310829818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Robot\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "##########APLICACIÓN DE ALGORITMOS DE MACHINE LEARNING \n",
        "\n",
        "#Separo la columna con la información de los sobrevivientes\n",
        "X = np.array(df_train.drop(['Survived'], axis=1))\n",
        "y = np.array(df_train['Survived'])\n",
        "\n",
        "#Separo los datos de \"train\" en entrenamiento y prueba para probar los algoritmos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "##Regresión logística\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "Y_pred = logreg.predict(X_test)\n",
        "print('Precisión Regresión Logística:')\n",
        "print(logreg.score(X_train, y_train))\n",
        "\n",
        "##Support Vector Machines\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "Y_pred = svc.predict(X_test)\n",
        "print('Precisión Soporte de Vectores:')\n",
        "print(svc.score(X_train, y_train))\n",
        "\n",
        "##KN neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn.fit(X_train, y_train)\n",
        "Y_pred = knn.predict(X_test)\n",
        "print('Precisión Vecinos más Cercanos:')\n",
        "print(knn.score(X_train, y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicción Regresión Logística:\n",
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         0\n",
            "2          894         0\n",
            "3          895         0\n",
            "4          896         0\n",
            "Predicción Soporte de Vectores:\n",
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         0\n",
            "2          894         0\n",
            "3          895         0\n",
            "4          896         0\n",
            "Predicción Vecinos más Cercanos:\n",
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         0\n",
            "2          894         0\n",
            "3          895         0\n",
            "4          896         0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Robot\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but SVC was fitted without feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\Robot\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "##########PREDICCIÓN UTILIZANDO LOS MODELOS\n",
        "\n",
        "ids = df_test['PassengerId']\n",
        "\n",
        "##Regresión logística\n",
        "prediccion_logreg = logreg.predict(df_test.drop('PassengerId', axis=1).values)\n",
        "out_logreg = pd.DataFrame({ 'PassengerId' : ids, 'Survived': prediccion_logreg })\n",
        "print('Predicción Regresión Logística:')\n",
        "print(out_logreg.head())\n",
        "\n",
        "\n",
        "##Support Vector Machines\n",
        "prediccion_svc = svc.predict(df_test.drop('PassengerId', axis=1))\n",
        "out_svc = pd.DataFrame({ 'PassengerId' : ids, 'Survived': prediccion_svc })\n",
        "print('Predicción Soporte de Vectores:')\n",
        "print(out_svc.head())\n",
        "\n",
        "##K neighbors\n",
        "prediccion_knn = knn.predict(df_test.drop('PassengerId', axis=1))\n",
        "out_knn = pd.DataFrame({ 'PassengerId' : ids, 'Survived': prediccion_knn })\n",
        "print('Predicción Vecinos más Cercanos:')\n",
        "print(out_knn.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
