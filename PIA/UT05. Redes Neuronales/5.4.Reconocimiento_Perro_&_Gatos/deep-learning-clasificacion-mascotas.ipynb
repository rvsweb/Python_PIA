{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizando mascotas con redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "En este cuaderno Jupyter aprenderás a clasificar imágenes de mascotas de forma automática, utilizando la potencia de las redes neuronales convolucionales, la técnica puntera que ha supuesto el _boom_ del Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "Habremos descargado el conjunto de datos **Oxford pets** del URL <https://www.robots.ox.ac.uk/~vgg/data/pets/> y extraído las imágenes a una carpeta `images`. La siguiente celda organiza los archivos en dos clases (perros y gatos) y en dos subconjuntos (entrenamiento y test) para facilitar las tareas posteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar e instalamos la libreria TensorFlow\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\robot\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias para la descarga y extracción de los archivos\n",
    "# La librería os nos permite interactuar con el sistema operativo y la librería tarfile nos permite trabajar con archivos comprimidos\n",
    "import os\n",
    "import tarfile\n",
    "# La librería urllib.request nos permite descargar archivos de la web\n",
    "# requests nos permite hacer peticiones a servidores web y trabajar con sus respuestas\n",
    "import urllib.request\n",
    "\n",
    "# Definir la URL del archivo comprimido\n",
    "url1 = \"https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\"\n",
    "\n",
    "url2 = \"https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz\"\n",
    "\n",
    "# Definir el directorio para almacenar el contenido extraído\n",
    "directory1 = \"images\"\n",
    "directory2 = \"annotations\"\n",
    "\n",
    "# Crea un directorio para almacenar los archivos extraídos\n",
    "os.makedirs(directory1, exist_ok=True)\n",
    "os.makedirs(directory2, exist_ok=True)\n",
    "\n",
    "# Descargar el archivo comprimido\n",
    "filename1, _ = urllib.request.urlretrieve(url1)\n",
    "filename2, _ = urllib.request.urlretrieve(url2)\n",
    "\n",
    "# Extraer el contenido del archivo comprimido\n",
    "with tarfile.open(filename1, \"r:gz\") as tar:\n",
    "  tar.extractall(directory1)\n",
    "\n",
    "# Extraer el contenido del archivo comprimido\n",
    "with tarfile.open(filename2, \"r:gz\") as tar:\n",
    "  tar.extractall(directory2)\n",
    "\n",
    "# Eliminar el archivo comprimido\n",
    "os.remove(filename1)\n",
    "os.remove(filename2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:52:19.533323800Z",
     "start_time": "2024-02-19T12:52:19.499115500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias para el desarrollo del modelo de machine learning\n",
    "import os\n",
    "\n",
    "# Definimos las rutas de las carpetas que contienen las imágenes y las anotaciones\n",
    "images_path = \"images/images\"\n",
    "# Anotaciones de las imágenes\n",
    "annotations_path = \"annotations/annotations\"\n",
    "\n",
    "# open() abre el archivo que se le pasa como argumento y readlines() lee todas las líneas del archivo y las devuelve como una lista\n",
    "trainval = open(os.path.join(annotations_path, \"trainval.txt\")).readlines()\n",
    "test = open(os.path.join(annotations_path, \"test.txt\")).readlines()\n",
    "\n",
    "# Creamos las carpetas necesarias para clasificar las imágenes en función de si son de gatos o de perros\n",
    "os.makedirs(os.path.join(images_path, \"train\", \"cats\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(images_path, \"train\", \"dogs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(images_path, \"test\", \"cats\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(images_path, \"test\", \"dogs\"), exist_ok=True)\n",
    "\n",
    "# Definimos una función que clasifica las imágenes en función de si son de gatos o de perros\n",
    "def classify_image(line, subset):\n",
    "# basename : Devuelve el último componente de la ruta que se le pasa como argumento\n",
    "    basename = line.split(\" \")[0]\n",
    "# species : Devuelve el tercer componente de la línea que se le pasa como argumento\n",
    "    species = line.split(\" \")[2]\n",
    "# subfolder : Es igual a \"cats\" si species es igual a \"1\" y \"dogs\" en caso contrario    \n",
    "    subfolder = \"cats\" if species == \"1\" else \"dogs\"\n",
    "# oldpath : Es igual a la ruta de la imagen    \n",
    "    oldpath = os.path.join(images_path, f\"{basename}.jpg\")\n",
    "# newpath : Es igual a la ruta de la imagen en función de si es de gato o de perro    \n",
    "    newpath = os.path.join(images_path, subset, subfolder, f\"{basename}.jpg\")\n",
    "# si oldpath : Es un archivo, se renombra a newpath\n",
    "    if os.path.isfile(oldpath):\n",
    "        # os.rename() renombra el archivo que se le pasa como primer argumento con el nombre que se le pasa como segundo argumento\n",
    "        os.rename(oldpath, newpath)\n",
    "\n",
    "# Clasificamos las imágenes en función de si son de gatos o de perros\n",
    "for line in trainval:\n",
    "    classify_image(line, \"train\")\n",
    "\n",
    "# Clasificamos las imágenes en función de si son de gatos o de perros\n",
    "for line in test:\n",
    "    classify_image(line, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-19T12:51:16.357929400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Robot\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 3680 images belonging to 2 classes.\n",
      "Found 3669 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias para el desarrollo del modelo de machine learning\n",
    "# La librería tensorflow.keras.preprocessing.image contiene la clase ImageDataGenerator \n",
    "# que permite generar lotes de tensores con datos de imagen en tiempo real\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Creamos un generador de datos de imagen para el conjunto de entrenamiento\n",
    "generador_entrenamiento = ImageDataGenerator()\n",
    "# flow_from_directory() genera lotes de tensores con datos de imagen en tiempo real\n",
    "datos_entrenamiento = generador_entrenamiento.flow_from_directory(\"images/train\")\n",
    "# ImageDataGenerator() genera lotes de tensores con datos de imagen en tiempo real\n",
    "generador_test = ImageDataGenerator()\n",
    "# flow_from_directory() genera lotes de tensores con datos de imagen en tiempo real\n",
    "datos_test = generador_test.flow_from_directory(\"images/test\", class_mode=None)\n",
    "# next(datos_test) devuelve el siguiente lote de tensores con datos de imagen\n",
    "algunas_imagenes = next(datos_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización\n",
    "\n",
    "Podemos visualizar algún ejemplo de imagen a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:51:17.684260700Z",
     "start_time": "2024-02-19T12:51:16.397928700Z"
    }
   },
   "outputs": [],
   "source": [
    "# matplotlib.pyplot es una colección de funciones que hacen que matplotlib funcione como MATLAB\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Mostramos algunas imágenes\n",
    "plt.imshow(algunas_imagenes[0]/255.)\n",
    "# plt.axis('off') elimina los ejes de la imagen para que no se muestren en el gráfico\n",
    "plt.axis('off')\n",
    "# plt.show() muestra el gráfico\n",
    "plt.show()\n",
    "# plt.imshow() muestra la imagen que se le pasa como argumento en el gráfico para que se muestre en el gráfico la siguiente imagen\n",
    "plt.imshow(algunas_imagenes[1]/255.)\n",
    "# plt.axis('off') elimina los ejes de la imagen para que no se muestren en el gráfico para que no se muestren en el gráfico\n",
    "plt.axis('off')\n",
    "# plt.show() muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del modelo\n",
    "\n",
    "Nuestro objetivo será crear un modelo capaz de responder a la pregunta \"¿Corresponde esta imagen a un gato o a un perro?\". En lugar de diseñar una nueva red neuronal desde cero, podemos cargar una red ya construida y, mejor aún, los parámetros optimizados para el conjunto de datos `Imagenet` de todo tipo de imágenes, de forma que nuestra red viene ya \"preparada\" para reconocer imágenes y no partimos de cero al entrenar. Esta estrategia se conoce como _transfer learning_.\n",
    "\n",
    "Importaremos la red InceptionV3 desde la biblioteca de modelos ya entrenados de Tensorflow. Esta red se basa en un componente llamado \"bloque Inception\": encadena varios de estos bloques para extraer información de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:51:17.690260100Z",
     "start_time": "2024-02-19T12:51:17.688263400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Robot\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Robot\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias para el desarrollo del modelo de machine learning\n",
    "# keras es una API de redes neuronales de alto nivel escrita en Python que se utiliza para el desarrollo de modelos de machine learning y deep learning su función principal es la de ser una interfaz de alto nivel para la biblioteca TensorFlow\n",
    "# applications contiene una serie de modelos pre-entrenados que se pueden utilizar para el desarrollo de modelos de machine learning y deep learning\n",
    "from tensorflow.keras import applications\n",
    "# InceptionV3 es una red neuronal convolucional que se utiliza para el desarrollo de modelos de machine learning y deep learning\n",
    "# Su función principal es la de ser una interfaz de alto nivel para la biblioteca TensorFlow\n",
    "inception = applications.InceptionV3(include_top=False, input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustes del modelo\n",
    "\n",
    "En la siguiente celda añadimos a la red InceptionV3 un par de capas que nos permiten obtener una predicción a partir de la información que haya inferido de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-19T12:51:17.693259900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Robot\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias para el desarrollo del modelo de machine learning\n",
    "# keras es una API de redes neuronales de alto nivel escrita en Python que se utiliza \n",
    "# para el desarrollo de modelos de machine learning y deep learning su función principal \n",
    "# es la de ser una interfaz de alto nivel para la biblioteca TensorFlow\n",
    "\n",
    "# tensorflow.keras.layers contiene las clases Flatten y Dense\n",
    "# La clase Flatten que se utiliza para aplanar los datos de entrada en una red neuronal  \n",
    "# La clase Dense que se utiliza para crear capas densas en una red neuronal\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "# tensorflow.keras.models contiene la clase Sequential que se utiliza para crear modelos de machine learning \n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Creamos la variable predictor que es igual a un modelo secuencial que contiene una capa Flatten, una capa Dense con 128 neuronas y una función de activación relu y una capa Dense con 2 neuronas y una función de activación softmax\n",
    "predictor = Sequential([\n",
    "    Flatten(), \n",
    "    # Dense() crea una capa densa en una red neuronal de 128 neuronas y una función de activación recibe como argumento la función de activación relu \n",
    "    # \"relu\" : es una función de activación que se utiliza en las redes neuronales\n",
    "    Dense(128, activation=\"relu\"), \n",
    "    # Dense() tiene 2 neuronas y una función de activación softmax \n",
    "    # \"softmax\" : se utiliza en las redes neuronales para clasificación y su función principal es la de convertir los valores de las neuronas en probabilidades\n",
    "    Dense(2, activation=\"softmax\")\n",
    "])\n",
    "# Sequential() crea un modelo secuencial que recibe como argumento una lista de capas\n",
    "# inception : es un modelo pre-entrenado que se utiliza como capa de extracción de características\n",
    "# predictor : es un modelo secuencial que se utiliza como clasificador\n",
    "modelo = Sequential([inception, predictor])\n",
    "# compile() compila el modelo que se le pasa como argumento\n",
    "# funcion optimizer : es el optimizador que se utiliza para el entrenamiento del modelo \n",
    "# El parametro \"adam\" es un optimizador que se utiliza en las redes neuronales\n",
    "# funcion loss : es la función de pérdida que se utiliza para el entrenamiento del modelo \n",
    "# El parametro \"categorical_crossentropy\" es una función de pérdida que se utiliza en las redes neuronales\n",
    "modelo.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "\n",
    "Una vez creado el modelo que ya tiene la estructura final para responder preguntas de \"sí/no\", ajustamos sus parámetros (que inicialmente son aleatorios) al conjunto de imágenes que vamos a utilizar para entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-19T12:51:17.697260300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "115/115 [==============================] - 425s 4s/step - loss: 0.0491\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 424s 4s/step - loss: 0.0187\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 426s 4s/step - loss: 0.0104\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 428s 4s/step - loss: 0.0279\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 428s 4s/step - loss: 0.0126\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 444s 4s/step - loss: 0.0294\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 430s 4s/step - loss: 0.0199\n",
      "Epoch 8/10\n",
      "115/115 [==============================] - 441s 4s/step - loss: 0.0417\n",
      "Epoch 9/10\n",
      "115/115 [==============================] - 459s 4s/step - loss: 0.0219\n",
      "Epoch 10/10\n",
      "115/115 [==============================] - 446s 4s/step - loss: 0.0233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24d4481cd10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelo.fit(datos_entrenamiento, epochs=50)\n",
    "# fit() entrena el modelo que se le pasa como argumento \n",
    "# datos_entrenamiento : es el conjunto de datos de entrenamiento que se utiliza para el entrenamiento del modelo\n",
    "# epochs : es el número de épocas que se utiliza para el entrenamiento del modelo\n",
    "modelo.fit(datos_entrenamiento, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción\n",
    "\n",
    "Nuestro modelo ya está listo. En la siguiente celda tomamos algunas imágenes del subconjunto de test (imágenes que nunca han sido vistas por la red neuronal) y comprobamos cuáles son las predicciones del modelo: ¿acertará todos los perros y gatos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-19T12:51:17.699265100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# next(datos_test) devuelve el siguiente lote de tensores con datos de imagen\n",
    "lote_test = next(datos_test)\n",
    "\n",
    "# modelo.predict(lote_test) devuelve las predicciones del modelo que se le pasa como argumento\n",
    "probs = modelo.predict(lote_test)\n",
    "# La librería numpy es una biblioteca de funciones matemáticas de alto nivel que se utiliza para el desarrollo de modelos de machine learning y deep learning\n",
    "import numpy as np\n",
    "# np.argmax(probs, -1) devuelve el índice del valor máximo de las predicciones\n",
    "# probs : es el conjunto de predicciones que se le pasa como argumento\n",
    "# -1 : es el eje en el que se busca el valor máximo\n",
    "clase = np.argmax(probs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-19T12:51:17.701262200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mostramos las predicciones para las imágenes del lote de test\n",
    "mostrar_imagenes = 10\n",
    "\n",
    "# Mostramos las predicciones para las imágenes del lote de test mediante un bucle for que recorre el rango de mostrar_imagenes \n",
    "for i in range(mostrar_imagenes):\n",
    "# plt.imshow() muestra la imagen que se le pasa como argumento en el gráfico para que se muestre en el gráfico la siguiente imagen \n",
    "    plt.imshow(lote_test[i]/255.)\n",
    "# plt.axis('off') elimina los ejes de la imagen para que no se muestren en el gráfico\n",
    "    plt.axis('off')\n",
    "# plt.show() muestra el gráfico    \n",
    "    plt.show()\n",
    "# print() muestra el texto que se le pasa como argumento y el resultado de la predicción que se le pasa como argumento \n",
    "    print(\"Predicción:\", \"perro\" if clase[i] else \"gato\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbd3e46b1708d560de477de7a0c449c08f8861f449ab70b5724e76cdf2c24cff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
